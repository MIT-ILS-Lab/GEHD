solver:
  run: "train"

  # logging and processing
  logdir: "main_model/logs/decoder"
  max_epoch: 5
  test_every_epoch: 1
  save_every_epoch: 2
  log_per_iter: 100

  # optimizer
  type: "adam"
  weight_decay: 0.0
  lr: 0.0001

  # learning rate
  lr_type: "step"
  milestones: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]
  gamma: 0.9

  # gradient accumulation
  accumulation_steps: 1

  # others
  progress_bar: true
  rand_seed: 22
  empty_cache: true
  ckpt: null
  clip_grad: 1.0

  # wandb
  wandb:
    project_name: "decoder"
    run_name: "my_decoder_run"

data:
  train:
    mode: "train"

    # data loading
    episodes: 20
    batch_size: 2
    num_workers: 4
    shuffle: true

    # environment
    env:
      data_path: "main_model/disk/mesh_cvrp_data.h5"
      sub_path: false

    # others
    disable: false

  test:
    mode: "test"

    # data loading
    episodes: 10
    batch_size: 10
    num_workers: 4
    shuffle: false

    # environment
    env:
      data_path: "main_model/disk/mesh_cvrp_data.h5"
      sub_path: false

    # others
    disable: false

model:
  embedding_dim: 128
  sqrt_embedding_dim: 11.313708498984761
  decoder_layer_num: 6
  qkv_dim: 16
  head_num: 8
  ff_hidden_dim: 512

  pretrained_encoder:
    in_channels: 6
    hidden_channels: 256
    out_channels: 256
    ckp_path: "main_model/logs/encoder/checkpoints/00500.solver.tar"
    mesh_path: "main_model/disk/meshes/sphere.obj"
