solver:
  run: train

  # logging and processing
  logdir: <Path to the log directory>
  max_epoch: 20000
  test_every_epoch: 1
  save_every_epoch: 500
  log_per_iter: 1

  # optimizer
  type: adamw
  weight_decay: 0.01  # default value of adamw
  lr: 0.00025

  # learning rate
  lr_type: poly
  lr_power: 0.9

  # gradient accumulation
  accumulation_steps: 32

  # others
  progress_bar: True
  rand_seed: -1 # fix the random seed if bigger than 0
  empty_cache: True # empty the cache periodically
  ckpt: "" # which checkpoint to load (none or null means no checkpoint)
  clip_grad: -1.0  # clip gradient norm (-1: disable)

  # wandb
  wandb:
    project_name: <Name of the wandb project>
    run_name: <Name of the wandb run>

data:
  preparation:
    #type of the mesh
    type: sphere # options are sphere, torus and 2d

    # paths to the different meshes
    path_to_mesh: <Path to the meshes>
    path_to_output_npz: <Path to the output npz files>
    path_to_output_filelist: <Path to the output filelist>

    # variables for splitting and distance generation
    split_ratio: 0.8
    num_train_sources: 300
    num_train_targets_per_source: 800
    num_test_sources: 400
    num_test_targets_per_source: 60

    # variables for filtering and running
    file_size_threshold: 12_048_576 # threshold to filter out large meshes
    threads: 1

  train:
    # data augmentations
    distort: True
    angle: [10, 10, 10]
    scale: 0
    jitter: 0.1

    # data loading
    location: ./
    filelist: <Path to the training filelist>
    batch_size: 1
    file_rep: 1 # number of times each file is repeated in the dataset

    shuffle: True
    num_workers: 0

    # others
    disable: False # wether or not to disable the training set
    take: -1  # number of samples used for training

  test:
    # data augmentations
    distort: False
    angle: [10, 10, 10]
    scale: 0
    jitter: 0.1

    # data loading
    location: ./
    filelist: <Path to the test filelist>
    batch_size: 1
    file_rep: 1 # number of times each file is repeated in the dataset

    shuffle: True
    num_workers: 0

    # others
    disable: False # wether or not to disable the test set
    take: -1  # number of samples used for testing

model:
  name: unet

  in_channels: 6 # input dimension of each vertices
  hidden_channels: 256 # hidden dimensions of the vertices
  out_channels: 32 # the final embedding dimension of each vertices

  conv_type: my # SAGE or my
  include_distance: True # only appliable when use dist conv. if true, the distance between points will be concated to the feature.

  normal_aware_pooling: True # when grid pooling, consider normal or not

  # visualization, will not affect the training/testing process, only visualization
  get_test_stat: False # if true, evaluate the test set before visualization
  output_dir: <Path to the output directory>
